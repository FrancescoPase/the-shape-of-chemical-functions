{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape of Molecules #\n",
    "\n",
    "In this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import random \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from giotto.graphs.create_clique_complex import CreateCliqueComplex, CreateBoundaryMatrices, CreateLaplacianMatrices    \n",
    "from giotto.graphs.heat_diffusion import HeatDiffusion\n",
    "from giotto.graphs.graph_entropy import GraphEntropy\n",
    "\n",
    "from molecules import mol_to_nx, compute_node_edge_entropy, bonds_type, graph_to_points\n",
    "from plotting import plot_entropies, plot_network_diffusion\n",
    "\n",
    "from rdkit import Chem \n",
    "from rdkit.Chem import Draw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Convert data to networkx Graph ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import molecules dataset and convert them: $\\textit{smiles}$ --> $\\textit{rdkit.Chem.rdchem.Mol}$ --> $\\textit{networkx.graph}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hiv.csv')\n",
    "df['g_mol'] = df['smiles'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "df.drop(\"smiles\", axis=1, inplace=True)\n",
    "g_mol = [mol_to_nx(df['g_mol'][i]) for i in range(df.shape[0]) if i != 559 and i!= 8097 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot one molecule ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g_mol[0]\n",
    "mol = [df['g_mol'][0]]\n",
    "\n",
    "nx.draw(g, pos=nx.spring_layout(g))\n",
    "Draw.MolsToGridImage(mol, molsPerRow=5, useSVG=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embedding for all molecules of the dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "taus_n = np.linspace(0,2,30)\n",
    "taus_e = np.linspace(0,2,30)\n",
    "#Embedding\n",
    "embeds = [compute_node_edge_entropy(x,i, taus_n, taus_e) for i,x in enumerate(g_mol) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the Embeddings \n",
    "import pickle \n",
    "pickle.dump(embeds, open(\"hiv_embeds.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load it and look at the dimensions \n",
    "import pickle\n",
    "embeds = pickle.load(open(\"hiv_embeds.pickle\", 'rb'))\n",
    "print(\"Dataset loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Bonds information #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds_type(g_mol)\n",
    "\n",
    "#Create a list with all nodes \n",
    "freq_type_bonds = list()\n",
    "for g in g_mol:\n",
    "    freq_type_bonds.extend(list(nx.get_node_attributes(g, 'bonds_one_hot').values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_type_bonds = np.array(freq_type_bonds)\n",
    "print(\"Total number of atoms in the dataset: {}\".format(freq_type_bonds.shape[0]))\n",
    "print(\"Entry size: {}\".format(freq_type_bonds.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Node Embeddding #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_nodes = list()\n",
    "for i in range(len(embeds)):\n",
    "    universal_nodes.extend(np.split(embeds[i][0][1:,:].T, embeds[i][0][0,:].shape[0]))\n",
    "universal_nodes = np.squeeze(np.array(universal_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_frq_nodes = [np.hstack([universal_nodes[x,:], freq_type_bonds[x,:]]) for x in range(universal_nodes.shape[0])]\n",
    "uni_frq_nodes = np.array(uni_frq_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_to_atom = graph_to_points(g_mol, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_n = KMeans(n_clusters=10)\n",
    "universal_class_nodes = kmeans_n.fit_transform(uni_frq_nodes)\n",
    " \n",
    "centroids_n = kmeans_n.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Edge Emebdding #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_edges = list()\n",
    "for i in range(len(embeds)):\n",
    "    universal_edges.extend(np.split(embeds[i][1][1:,:].T, embeds[i][1][0,:].shape[0]))\n",
    "universal_edges = np.squeeze(np.array(universal_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i, g in enumerate(g_mol):\n",
    "    d_e = dict()\n",
    "    for e in g.edges():\n",
    "        b = int(g.get_edge_data(e[0], e[1])['bond_type'])\n",
    "        d_e[e] = np.zeros(4)\n",
    "        if (b == 12):\n",
    "            d_e[e][3] = 1\n",
    "        else:\n",
    "            d_e[e][b-1] = 1\n",
    "    nx.set_edge_attributes(g, name='bonds_one_hot', values=d_e)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "freq_type_bonds_edge = list()\n",
    "for g in g_mol:\n",
    "    freq_type_bonds_edge.extend(list(nx.get_edge_attributes(g, 'bonds_one_hot').values()))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "uni_frq_edge = list()\n",
    "for x in range(universal_edge.shape[0]):\n",
    "    uni_frq_edge.append(np.hstack([universal_edge[x,:], freq_type_bonds_edge[x,:]]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_e = KMeans(n_clusters=10)\n",
    "universal_class_edge = kmeans_e.fit_transform(universal_edges)\n",
    "\n",
    "centroids_e = kmeans_e.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_to_bonds = graph_to_points(g_mol, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Molecule sizes frequency\n",
    "\n",
    "dims = [t.number_of_nodes() for t in g_mol]\n",
    "_ = plt.hist(dims, bins=100)\n",
    "_ = plt.title(\"Molecule sizes frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data with universal embedding #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = np.zeros((universal_nodes.shape[0], 10))\n",
    "for x in range(len(universal_points)):\n",
    "    one_hot_encoded[x][universal_class[x]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Encoded\n",
    "# soft_encoded_node = np.zeros((uni_frq.shape[0], 10))\n",
    "soft_encoded_node = [[ np.exp( - (np.linalg.norm(uni_frq_nodes[x]- centroids_n[c], 2) ** 2) / 2) for c in range(10)] for x in range(uni_frq_nodes.shape[0])]\n",
    "soft_encoded_node = np.array(soft_encoded_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize\n",
    "for x in soft_encoded_node:\n",
    "    x /= np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data for each graph\n",
    "x_data_node = list()\n",
    "for i in range(len(g_mol)):\n",
    "    #if (g_mol[i].number_of_nodes() > 10 and g_mol[i].number_of_nodes() < 100):\n",
    "    #v = np.zeros((soft_encoded_node[0].shape[0]))\n",
    "    #v = np.zeros((one_hot_encoded[0].shape[0]))\n",
    "    #for n in graph_to_points[i]:\n",
    "        #v += soft_encoded_node[n]\n",
    "        #v += one_hot_encoded[n]\n",
    "        #x_data.append(np.hstack([v,t]))\n",
    "        \n",
    "    x_data_node.append(np.sum([soft_encoded_node[n] for n in mol_to_atom[i]], axis=0))\n",
    "x_data_node = np.array(x_data_node)\n",
    "x_data_node.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "one_hot_encoded_edge = np.zeros((universal_class_edge.shape[0], 10))\n",
    "for x in range(len(universal_edge)):\n",
    "    one_hot_encoded_edge[x][universal_class_edge[x]] = 1\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Encoded\n",
    "soft_encoded_edge = [[ np.exp( - (np.linalg.norm(universal_edges[x]- centroids_e[c], 2) ** 2) / 2) for c in range(10)] for x in range(universal_edges.shape[0])]\n",
    "soft_encoded_edge = np.array(soft_encoded_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soft_encoded_edge:\n",
    "    x /= np.sum(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create edge data for each graph\n",
    "x_data_edge = list()\n",
    "for i in range(len(g_mol)):\n",
    "    #if (g_mol[i].number_of_nodes() > 10 and g_mol[i].number_of_nodes() < 100):\n",
    "        #v = np.zeros((soft_encoded_edge[0].shape[0]))\n",
    "        #v = np.zeros((one_hot_encoded_edge[0].shape[0]))\n",
    "        #for n in graph_to_edges[i]:\n",
    "            #v += soft_encoded_edge[n]\n",
    "            #v += one_hot_encoded_edge[n]\n",
    "    x_data_edge.append(np.sum([soft_encoded_edge[n] for n in mol_to_bonds[i]], axis=0))\n",
    "x_data_edge = np.array(x_data_edge)\n",
    "x_data_edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.hstack([x_data_node, x_data_edge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data -= np.mean(x_data, axis=0)\n",
    "x_data /= (np.max(x_data, axis=0) - np.min(x_data, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare y_data\n",
    "y_data = [df['HIV_active'][i] for i in range(df.shape[0]) if i != 8079 and i != 559]\n",
    "y_data = np.array(y_data)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.arange(41911)\n",
    "random.Random(10).shuffle(f)\n",
    "train = f[:35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f[35000:35010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#np.random.seed=np.random.randint(0,123456)\n",
    "np.random.shuffle(train)\n",
    "\n",
    "\n",
    "\n",
    "i_train = train[:29000]\n",
    "i_val = train[29000:35000]\n",
    "i_test = f[35000:]\n",
    "\n",
    "x_train = x_data[i_train, :]\n",
    "x_val = x_data[i_val, :] \n",
    "\n",
    "y_train = y_data[i_train]\n",
    "y_val = y_data[i_val]\n",
    "\n",
    "x_test = np.array([np.array(x_data[i,:]) for i in f[35000:]])\n",
    "y_test = np.array([y_data[i] for i in f[35000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # define the keras model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(x_train, y_train, epochs=100,validation_data=(x_val, y_val), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate the keras model\n",
    "\n",
    "pe, accuracy = model.evaluate(x_val, y_val)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = model.predict(x_train)\n",
    "p_val = model.predict(x_val)\n",
    "p_test = model.predict(x_test)\n",
    "\n",
    "print(\" Train AUC-ROC :\")\n",
    "print(roc_auc_score(y_train, p_train))\n",
    "\n",
    "print(\" Valid AUC-ROC :\")\n",
    "print(roc_auc_score(y_val, p_val))\n",
    "\n",
    "print(\" Test AUC-ROC :\")\n",
    "print(roc_auc_score(y_test, p_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py35)",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
