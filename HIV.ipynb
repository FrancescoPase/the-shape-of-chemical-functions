{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape of Molecules #\n",
    "\n",
    "In this notebook we provide an innovative pipeline that makes it possible to find interesting and meaningful structural features by exploiting the package $\\href{https://giotto.ai/}{giotto learn}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import random \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from giotto.graphs.create_clique_complex import CreateCliqueComplex, CreateBoundaryMatrices, CreateLaplacianMatrices    \n",
    "from giotto.graphs.heat_diffusion import HeatDiffusion\n",
    "from giotto.graphs.graph_entropy import GraphEntropy\n",
    "\n",
    "from molecules import mol_to_nx, compute_node_edge_entropy, bonds_type, graph_to_points, bonds_type_to_edge\n",
    "from plotting import plot_entropies, plot_network_diffusion\n",
    "\n",
    "from rdkit import Chem \n",
    "from rdkit.Chem import Draw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Convert data to networkx Graph ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import molecules dataset and convert them: $\\textit{smiles}$ --> $\\textit{rdkit.Chem.rdchem.Mol}$ --> $\\textit{networkx.graph}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and convert data\n",
    "df = pd.read_csv('hiv.csv')\n",
    "df['g_mol'] = df['smiles'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "df.drop(\"smiles\", axis=1, inplace=True)\n",
    "g_mol = [mol_to_nx(df['g_mol'][i]) for i in range(df.shape[0]) if i != 559 and i!= 8097 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot one molecule ##\n",
    "\n",
    "We plot here one example of a molecule: in the first plot it is represented as a $\\textit{Mol}$ object of the $\\textit{rdkit}$ module; in the second one the molecule is plotted as a graph by using the $\\textit{networkx}$ package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose one random molecule\n",
    "g = g_mol[0]\n",
    "mol = [df['g_mol'][0]]\n",
    "plt.figure(figsize=(6,3))\n",
    "nx.draw(g, pos=nx.spring_layout(g, iterations=1000))\n",
    "Draw.MolsToGridImage(mol, molsPerRow=5, useSVG=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings for all atoms and bonds in the dataset ##\n",
    "\n",
    "Here the embeddings for all atoms and bonds presented in the dataset are computed. In particular it is possible to choose different hyperparameters: the number of points in time at which the heat diffusions have to be sampled and the last sample instant. In this example the different samples are linearly spaced in time but of course it possible to choose them differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "taus_n = np.linspace(0,2,30)\n",
    "taus_e = np.linspace(0,2,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "embeds = [compute_node_edge_entropy(x,i, taus_n, taus_e) for i,x in enumerate(g_mol) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Embeddings ##\n",
    "\n",
    "This part of the notebook let the users save and reload the found embeddings for all molecules and embedding. It can be used to save time when trying different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the Embeddings \n",
    "import pickle \n",
    "pickle.dump(embeds, open(\"hiv_embeds.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load it and look at the dimensions \n",
    "import pickle\n",
    "embeds = pickle.load(open(\"hiv_embeds_40.pickle\", 'rb'))\n",
    "print(\"Dataset loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Bonds information #\n",
    "\n",
    "We now add to each node chemical informatino about the type of bonds they make with neighbor nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds_type(g_mol)\n",
    "bonds_type_to_edge(g_mol)\n",
    "\n",
    "#Create a list with all nodes \n",
    "freq_type_bonds = list()\n",
    "for g in g_mol:\n",
    "    freq_type_bonds.extend(list(nx.get_node_attributes(g, 'bonds_one_hot').values()))\n",
    "    \n",
    "freq_type_bonds_edge = list()\n",
    "for g in g_mol:\n",
    "    freq_type_bonds_edge.extend(list(nx.get_edge_attributes(g, 'bonds_one_hot').values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_type_bonds = np.array(freq_type_bonds)\n",
    "freq_type_bonds_edge = np.array(freq_type_bonds_edge)\n",
    "print(\"Total number of atoms in the dataset: {}\".format(freq_type_bonds.shape[0]))\n",
    "print(\"Total number of bonds in the dataset: {}\".format(freq_type_bonds_edge.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Node Embeddding #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_nodes = list()\n",
    "for i in range(len(embeds)):\n",
    "    universal_nodes.extend(np.split(embeds[i][0][1:,:].T, embeds[i][0][0,:].shape[0]))\n",
    "universal_nodes = np.squeeze(np.array(universal_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_frq_nodes = [np.hstack([universal_nodes[x,:], freq_type_bonds[x,:]]) for x in range(universal_nodes.shape[0])]\n",
    "uni_frq_nodes = np.array(uni_frq_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_to_atom = graph_to_points(g_mol, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_n = KMeans(n_clusters=10)\n",
    "universal_class_nodes = kmeans_n.fit_transform(uni_frq_nodes)\n",
    " \n",
    "centroids_n = kmeans_n.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Edge Emebdding #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_edges = list()\n",
    "for i in range(len(embeds)):\n",
    "    universal_edges.extend(np.split(embeds[i][1][1:,:].T, embeds[i][1][0,:].shape[0]))\n",
    "universal_edges = np.squeeze(np.array(universal_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_frq_edges = [np.hstack([universal_edges[x,:], freq_type_bonds_edge[x,:]]) for x in range(universal_edges.shape[0])]\n",
    "uni_frq_edges = np.array(uni_frq_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_to_bonds = graph_to_points(g_mol, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_e = KMeans(n_clusters=10)\n",
    "universal_class_edge = kmeans_e.fit_transform(uni_frq_edges)\n",
    "\n",
    "centroids_e = kmeans_e.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data with universal embedding #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "one_hot_encoded = np.zeros((universal_nodes.shape[0], 10))\n",
    "for x in range(len(universal_points)):\n",
    "    one_hot_encoded[x][universal_class[x]] = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Encoded\n",
    "# soft_encoded_node = np.zeros((uni_frq.shape[0], 10))\n",
    "soft_encoded_node = [[ np.exp( - (np.linalg.norm(uni_frq_nodes[x]- centroids_n[c], 2) ** 2) / 2) for c in range(10)] for x in range(uni_frq_nodes.shape[0])]\n",
    "soft_encoded_node = np.array(soft_encoded_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data for each graph\n",
    "x_data_node = [ np.sum([soft_encoded_node[n] for n in mol_to_atom[i]], axis=0) for i in range(len(g_mol))]\n",
    "x_data_node = np.array(x_data_node)\n",
    "print(\"Check shape of x_data_node: {}\".format(x_data_node.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "one_hot_encoded_edge = np.zeros((universal_class_edge.shape[0], 10))\n",
    "for x in range(len(universal_edge)):\n",
    "    one_hot_encoded_edge[x][universal_class_edge[x]] = 1\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Encoded\n",
    "soft_encoded_edge = [[ np.exp( - (np.linalg.norm(uni_frq_edges[x]- centroids_e[c], 2) ** 2) / 2) for c in range(10)] for x in range(universal_edges.shape[0])]\n",
    "soft_encoded_edge = np.array(soft_encoded_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_edge = [ np.sum([soft_encoded_edge[n] for n in mol_to_bonds[i]], axis=0)  for i in range(len(g_mol))]\n",
    "x_data_edge = np.array(x_data_edge)\n",
    "print(\"Check shape of x_data_edge: {}\".format(x_data_edge.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.hstack([x_data_node, x_data_edge])\n",
    "x_data -= np.mean(x_data, axis=0)\n",
    "x_data /= (np.max(x_data, axis=0) - np.min(x_data, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare y_data\n",
    "y_data = [df['HIV_active'][i] for i in range(df.shape[0]) if i != 8079 and i != 559]\n",
    "y_data = np.array(y_data)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "f = np.arange(41911)\n",
    "random.Random(10).shuffle(f)\n",
    "train = f[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train)\n",
    "\n",
    "i_train = train[:36000]\n",
    "i_val = train[30000:36000]\n",
    "i_test = f[36000:]\n",
    "\n",
    "x_train = x_data[i_train, :]\n",
    "x_val = x_data[i_val, :] \n",
    "\n",
    "y_train = y_data[i_train]\n",
    "y_val = y_data[i_val]\n",
    "\n",
    "x_test = np.array([np.array(x_data[i,:]) for i in f[36000:]])\n",
    "y_test = np.array([y_data[i] for i in f[36000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # define the keras model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=100,validation_data=(x_val, y_val), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "pe, accuracy = model.evaluate(x_val, y_val)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "p_train = model.predict(x_train)\n",
    "p_val = model.predict(x_val)\n",
    "p_test = model.predict(x_test)\n",
    "\n",
    "print(\" Train AUC-ROC : {}\".format(roc_auc_score(y_train, p_train)))\n",
    "\n",
    "print(\" Valid AUC-ROC : {}\".format(roc_auc_score(y_val, p_val)))\n",
    "\n",
    "print(\" Test AUC-ROC : {}\".format(roc_auc_score(y_test, p_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py35)",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
